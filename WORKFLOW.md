# Project Workflow

This document outlines the standard workflow for training and evaluating agents in the TraderNet-CRv2 project (PyTorch version).

## 1. Data Preparation
Before training, ensure you have the necessary datasets.
- **Script**: `database/build_dataset.py` (or similar data building logic).
- **Input**: Raw OHLCV data (e.g., from Binance).
- **Output**: Processed CSV files in `database/storage/datasets/`.
- **Action**: Ensure your target dataset (e.g., `DOGEUSDT.csv`) exists in the storage directory.

## 2. Training
Train the agents (PPO, DQN) using the processed data.
- **Script**: `train.py` (Standard) or `train_smurf.py` (Smurfing strategy).
- **Configuration**: Edit the `if __name__ == "__main__":` block in the script to set:
    - `datasets_dict`: Which coins to train on.
    - `agents_configs`: Agent hyperparameters (e.g., `train_iterations`, `device`).
    - `train_dict`: Environment settings (fees, timeframe, etc.).
- **Command**:
  ```bash
  python train.py
  ```
- **Output**:
  - Checkpoints: `database/storage/checkpoints/experiments/...`
  - Logs: Tensorboard logs in the checkpoint directory.
  - CSV Results: `experiments/tradernet/...` (Metrics and PnL).

## 3. Evaluation
Evaluate the trained models on unseen data (or specific test sets).
- **Script**: `eval.py`.
- **Configuration**: Ensure `datasets_dict` and `agent_dict` match what you trained.
- **Command**:
  ```bash
  python eval.py
  ```
- **Output**:
  - Metrics CSV: `experiments/tradernet/..._metrics.csv`.
  - Cumulative PnL CSV: `experiments/tradernet/..._eval_cumul_pnls.csv`.

## 4. Visualization (Coming Soon)
Visualize the training and evaluation results.
- **Script**: `plot_results.py` (To be created from `create_plots.ipynb`).
- **Input**: CSV files generated by `train.py` and `eval.py`.
- **Output**: JPG/PNG plots in `experiments/...`.
